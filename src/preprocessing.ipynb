{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from os import path as osp\n",
    "from spellchecker import SpellChecker\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Main text file was seperated into three files based on the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '../data/assignment_data.txt'\n",
    "\n",
    "assignment_file = \"../data/student_corse_feedback.txt\"\n",
    "twitter_data = \"../data/twitter_data.txt\"\n",
    "research_file = \"../data/research_data.txt\"\n",
    "\n",
    "preview_length = 100\n",
    "\n",
    "output_location = '../output'\n",
    "\n",
    "class TEXT:\n",
    "    rsh = 'research'\n",
    "    twt = 'twitter'\n",
    "    asn = 'assignment'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "data['research'] = open(research_file, mode = 'r', encoding='utf-8').read()\n",
    "data['twitter'] = open(twitter_data, mode = 'r', encoding='utf-8').read()\n",
    "data['assignment'] = open(assignment_file, mode = 'r', encoding='utf-8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Neural network models have shown their promising opportunities for multi-task\\nlearning, which focus '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['research'][:preview_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reminds me of Liberal Immigration Fraudster Monsef avoiding deportation from Canada. #cdnpoli #LPC #'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['twitter'][:preview_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Honestly last seven lectures are good. Lectures are understandable. Lecture slides are very useful t'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['assignment'][:preview_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(text_lines, file_name):\n",
    "    full_path = osp.join(output_location, file_name)\n",
    "    dir_path = osp.dirname(full_path)\n",
    "    if not osp.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "        \n",
    "    with open(full_path, 'w') as fp:\n",
    "#         print(text_lines)\n",
    "        for line in text_lines:\n",
    "#             print(line)\n",
    "            fp.write(line + ' ')\n",
    "    print(\"Written to {}\".format(full_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Tockenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tockenize_text(words):\n",
    "    return word_tokenize(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Student Course Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written to ../output/tockenize/assignment_output.txt\n"
     ]
    }
   ],
   "source": [
    "student_feedback_tockenize = tockenize_text(data[TEXT.asn])\n",
    "write_to_file(student_feedback_tockenize, 'tockenize/{}_output.txt'.format(TEXT.asn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Twitter Feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written to ../output/tockenize/twitter_output.txt\n"
     ]
    }
   ],
   "source": [
    "twitter_data_tockenize = tockenize_text(data[TEXT.twt])\n",
    "write_to_file(twitter_data_tockenize, 'tockenize/{}_output.txt'.format(TEXT.twt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Research Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written to ../output/tockenize/research_output.txt\n"
     ]
    }
   ],
   "source": [
    "research_data_tockenize = tockenize_text(data[TEXT.rsh])\n",
    "write_to_file(research_data_tockenize, 'tockenize/{}_output.txt'.format(TEXT.rsh))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Isolated word correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spell_ckecking(tockens):\n",
    "    spell = SpellChecker(distance=2)\n",
    "    mispelled = spell.unknown(tockens)\n",
    "    pairs = []\n",
    "    print(\"Mispelled count: {}\".format(len(mispelled)))\n",
    "    for i, word in enumerate(mispelled):\n",
    "        correction = spell.correction(word)\n",
    "        print('{:2} - \"{}\" is corrected as \"{}\"'.format(i, word, correction))\n",
    "        pairs.append((word, correction))\n",
    "        if i == 5:\n",
    "            break\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Student Course Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mispelled count: 14\n",
      " 0 - \"''\" is corrected as \"d'\"\n",
      " 1 - \"speed.a\" is corrected as \"speed\"\n",
      " 2 - \"examples.lectures\" is corrected as \"examples.lectures\"\n",
      " 3 - \"undersatand\" is corrected as \"understand\"\n",
      " 4 - \"..\" is corrected as \"p.\"\n",
      " 5 - \"class.it\" is corrected as \"classic\"\n"
     ]
    }
   ],
   "source": [
    "word_pairs = spell_ckecking(student_feedback_tockenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Twitter Feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mispelled count: 87\n",
      " 0 - \"//t.co/uibsezoqas\" is corrected as \"//t.co/uibsezoqas\"\n",
      " 1 - \"c��_\" is corrected as \"c��_\"\n",
      " 2 - \"https\" is corrected as \"steps\"\n",
      " 3 - \"//t.co/becgusy2i6\" is corrected as \"//t.co/becgusy2i6\"\n",
      " 4 - \"//t.co/cneywn40x3\" is corrected as \"//t.co/cneywn40x3\"\n",
      " 5 - \"fasttraffic\" is corrected as \"fasttraffic\"\n"
     ]
    }
   ],
   "source": [
    "word_pairs = spell_ckecking(twitter_data_tockenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Research Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mispelled count: 16\n",
      " 0 - \"�infantile�\" is corrected as \"infantile\"\n",
      " 1 - \"task-specific\" is corrected as \"task-specific\"\n",
      " 2 - \"luong\" is corrected as \"long\"\n",
      " 3 - \"multi-task\" is corrected as \"multi-track\"\n",
      " 4 - \"shared-private\" is corrected as \"shared-private\"\n",
      " 5 - \"task-dependent\" is corrected as \"task-dependent\"\n"
     ]
    }
   ],
   "source": [
    "word_pairs = spell_ckecking(research_data_tockenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Context Sensitive word correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "from symspellpy.symspellpy import SymSpell, Verbosity\n",
    "word_length = 2\n",
    "prefix_length = 7\n",
    "sym_spell = SymSpell(word_length, prefix_length)\n",
    "print(\"Corpus file not found\") if not sym_spell.create_dictionary(\"../data/big.txt\") else print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "preview = 10\n",
    "def correct_tocknized_text(words):\n",
    "    corr_count = 0\n",
    "    corrected_words = []\n",
    "    for i, word in enumerate(words[:-word_length+1]):\n",
    "        word_set = [words[i+j] for j in range(word_length)]\n",
    "        _input = ' '.join(word_set)\n",
    "        result = sym_spell.word_segmentation(_input)\n",
    "        correction = result.corrected_string\n",
    "        if correction.lower() != _input.lower() and preview < corr_count:\n",
    "            corr_count += 1\n",
    "            print('\"{}\" is corrected as \"{}\"'.format(_input, correction))\n",
    "        corrected_words.append(correction.split(' ')[0])\n",
    "    corrected_words.append(correction.split(' ')[1])\n",
    "    return corrected_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Student Course Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Honestly', 'last', 'seven', 'lectures', 'are', 'good', 'a', 'Lectures', 'are', 'understandable', 'a', 'Lecture', 'sides', 'are', 'very', 'useful', 'to', 'self', 'also', 'a', 'The', 'given', 'opportunity', 'to', 'ask', 'questions', 'from', 'the', 'lecturer', 'is', 'appreciative', 'a', 'of', 'Good', 'a', 'a', 'a', 'br', 'a', 'a', 'please', 'do', 'reap', 'at', 'class', 'starting', 'it', 'a', 'a', '39', 'a', 's', 'better', 'for', 'us', 'a', 'a', 'br', 'a', 'a', 'sometimes', 'teaching', 'speed', 'is', 'very', 'high', 'a', 'a', 'br', 'a', 'a', 'a', 'br', 'a', 'a', 'Thanks', 'a', 'a', 'a', 'a', 'br', 'a', 'a', 'of', 'The', 'lectures', 'are', 'good', 'of', 'but', 'a', 'bit', 'speed', 'in', 'class', 'working', 'activity', 'is', 'a', 'must', 'ones', 'please', 'take', 'another', 'hour', 'in', 'thursdays', \"madame'\", \"'\", 'a', 'br', 'a', 'a', 'We', 'can', 'hear', 'your', 'voice', 'clearly', 'and', 'can', 'understand', 'the', 'things', 'you', 'teach', 'a', 'Presentation', 'sides', 'also', 'good', 'source', 'to', 'refer', 'a', 'of', 'you', 'can', 'do', 'more', 'example', 'questions', 'within', 'the', 'classroom', 'and', 'it', 'will', 'help', 'us', 'to', 'understand', 'the', 'principles', 'well', 'a', 'a', 'br', 'a', \"a'\", \"'\", 'Lectures', 'was', 'well', 'structures', 'and', 'well', 'organized', 'a', 'It', 'was', 'easy', 'to', 'understand', 'a', 'Lecture', 'sides', 'and', 'laws', 'were', 'also', 'well', 'organized', 'a', 'Lectures', 'were', 'good', 'a', 'understandable', 'a', 'The', 'lecture', 'sides', 'were', 'well', 'organized', 'and', 'the', 'examples', 'done', 'in', 'the', 'class', 'helped', 'a', 'lot', 'to', 'learn', 'this', 'new', 'language', 'and', 'also', 'the', 'principles', 'of', 'Top', 'a', 'Motivate', 'to', 'well', 'a', 'Would', 'have', 'been', 'better', 'if', 'we', 'discussed', 'more', 'about', 'the', 'solutions', 'of', 'coming', 'exercises', 'a', 'I', 'think', 'i', 'learned', 'a', 'lot', 'from', 'the', 'codes', 'you', 'write', 'in', 'the', 'board', 'a', 'When', 'i', 'compare', 'my', 'codes', 'with', 'yours', 'i', 'can', 'learn', 'about', 'my', 'mistakes', 'and', 'good', 'coming', 'practices', 'that', 'i', 'should', 'follow', 'a', 'There', 'fore', 'i', 'think', 'it', 'would', 'be', 'great', 'if', 'we', 'can', 'discuss', 'more', 'examples', 'in', 'the', 'class', 'a', 'madam', 'explained', 'the', 'top', 'concepts', 'clearly', 'with', 'examples', 'were', 'interesting', 'want', 'more', 'scenario', 'examples', 'and', 'answers', 'with', 'explanations', 'in', 'future', 'a', 'I', 'satisfy', 'about', 'first', '7', 'lectures', 'a', 'That', 'way', 'of', 'teaching', 'is', 'really', 'good', 'for', 'coming', 'lectures', 'too', 'a', 'lectures', 'are', 'very', 'good', 'a', 'take', 'good', 'effort', 'to', 'make', 'understand', 'every', 'student', 'in', 'the', 'room', 'a', 'very', 'helpful', 'a', 'I', 'was', 'able', 'to', 'obtain', 'a', 'clear', 'picture', 'about', 'Top', 'and', 'its', 'concepts', 'a', 'of', 'lecture', 'sides', 'a', 'explanations', 'were', 'very', 'clear', 'a', 'a', 'br', 'a', 'a', 'it', 'a', 'a', '39', 'a', 's', 'very', 'good', 'to', 'letting', 'ask', 'questions', 'and', 'explain', 'again', 'with', 'suitable', 'examples', 'a', 'a', 'br', 'a', 'a', 'sometimes', 'a', 'some', 'codes', 'on', 'white', 'board', 'were', 'unclear', 'at', 'the', 'back', 'a', 'a', 'br', 'a', 'a', 'overall', 'very', 'good', 'a', 'a', 'a', 'a', 'br', 'a', \"a'\", \"'\", 'The', 'lectures', 'were', 'good', 'and', 'clear', 'a', 'And', 'they', 'were', 'a', 'a', '39', 'a', 't', 'too', 'fast', 'a', 'Writing', 'code', 'was', 'somewhat', 'confusing', 'because', 'I', 'did', 'a', 'a', '39', 'a', 't', 'know', 'cava', 'before', 'a', 'Actually', 'teaching', 'is', 'very', 'good', 'and', 'can', 'understand', 'easily', 'the', 'concepts', 'by', 'examples', 'which', 'are', 'given', 'in', 'the', 'classic', 'will', 'be', 'more', 'helpful', 'if', 'provide', 'solved', 'questions', 'as', 'well', 'a', 'a', 'thank']\n"
     ]
    }
   ],
   "source": [
    "print(correct_tocknized_text(student_feedback_tockenize))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Twitter Feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Immigration Fraudster\" is corrected as \"Immigration Frauds her\"\n",
      "\"Fraudster Monsef\" is corrected as \"Frauds her Money\"\n",
      "\"Monsef avoiding\" is corrected as \"Money avoiding\"\n",
      "\"avoiding deportation\" is corrected as \"avoiding importation\"\n",
      "\"deportation from\" is corrected as \"importation from\"\n",
      "\"Canada .\" is corrected as \"Canada a\"\n",
      "\". #\" is corrected as \"a a\"\n",
      "\"# cdnpoli\" is corrected as \"a campo li\"\n",
      "\"cdnpoli #\" is corrected as \"campo li a\"\n",
      "\"# LPC\" is corrected as \"alps\"\n",
      "\"LPC #\" is corrected as \"Lock\"\n",
      "\"# CPCLDR��_\" is corrected as \"a Could R��_\"\n",
      "\"CPCLDR��_ https\" is corrected as \"Could R��_ http\"\n",
      "\"https :\" is corrected as \"http a\"\n",
      "\": //t.co/ZOZOSe1CqQ\" is corrected as \"a it icon Loose 1 Can\"\n",
      "\"//t.co/ZOZOSe1CqQ #\" is corrected as \"it icon Loose 1 Can a\"\n",
      "\"# immigration\" is corrected as \"a immigration\"\n",
      "\"immigration #\" is corrected as \"immigration a\"\n",
      "\"# integration\" is corrected as \"a integration\"\n",
      "\"integration #\" is corrected as \"integration a\"\n",
      "\"# canada\" is corrected as \"a canada\"\n",
      "\"canada https\" is corrected as \"canada http\"\n",
      "\"https :\" is corrected as \"http a\"\n",
      "\": //t.co/M5cKGyvV8F\" is corrected as \"a it icon Mack you of\"\n",
      "\"//t.co/M5cKGyvV8F We\" is corrected as \"it icon Mack you of We\"\n",
      "\"the UK\" is corrected as \"the Up\"\n",
      "\"UK economy\" is corrected as \"Up economy\"\n",
      "\"economy .\" is corrected as \"economy a\"\n",
      "\". Same\" is corrected as \"a Same\"\n",
      "\"Australia &\" is corrected as \"Australia a\"\n",
      "\"& amp\" is corrected as \"a amp\"\n",
      "\"amp ;\" is corrected as \"amp a\"\n",
      "\"; Canada\" is corrected as \"a Canada\"\n",
      "\"Canada .\" is corrected as \"Canada a\"\n",
      "\". https\" is corrected as \"a http\"\n",
      "\"https :\" is corrected as \"http a\"\n",
      "\": //t.co/99mYliuOes\" is corrected as \"a it icon 99 my does\"\n",
      "\"//t.co/99mYliuOes Is\" is corrected as \"it icon 99 my does Is\"\n",
      "\"new Manitoba\" is corrected as \"new Monitor a\"\n",
      "\"Manitoba immigration\" is corrected as \"Monitor a immigration\"\n",
      "\"tax ?\" is corrected as \"tax a\"\n",
      "\"? https\" is corrected as \"a http\"\n",
      "\"https :\" is corrected as \"http a\"\n",
      "\": //t.co/LsG7C3vLe9\" is corrected as \"a it coils 73 let\"\n",
      "\"//t.co/LsG7C3vLe9 Canada\" is corrected as \"it coils 73 let Canada\"\n",
      "\"influence modernistic\" is corrected as \"influence modern is tic\"\n",
      "\"modernistic delhi\" is corrected as \"modern is tic delhi\"\n",
      "\"yet abhinav\" is corrected as \"yet china v\"\n",
      "\"abhinav :\" is corrected as \"china v a\"\n",
      "\": XKofy\" is corrected as \"a Of y\"\n",
      "\"XKofy https\" is corrected as \"Of y http\"\n",
      "\"https :\" is corrected as \"http a\"\n",
      "\": //t.co/becgusY2i6\" is corrected as \"a it icon because 26\"\n",
      "\"//t.co/becgusY2i6 Canada\" is corrected as \"it icon because 26 Canada\"\n",
      "\"to ���Substantially\" is corrected as \"to of substantially\"\n",
      "\"���Substantially Increase\" is corrected as \"of substantially Increase\"\n",
      "\"Numbers https\" is corrected as \"Numbers http\"\n",
      "\"https :\" is corrected as \"http a\"\n",
      "\": //t.co/nEFw30MRaa\" is corrected as \"a it cone Fwom Ran\"\n",
      "\"//t.co/nEFw30MRaa https\" is corrected as \"it cone Fwom Ran http\"\n",
      "\"https :\" is corrected as \"http a\"\n",
      "\": //t.co/cyI867PZRV\" is corrected as \"a of to cocci 167 Or\"\n",
      "\"//t.co/cyI867PZRV M��me\" is corrected as \"of to cocci 167 Or Meme\"\n",
      "\"M��me les\" is corrected as \"Meme les\"\n",
      "\"les #\" is corrected as \"les a\"\n",
      "\"# USA=pays\" is corrected as \"susan pays\"\n",
      "\"USA=pays d'immigration\" is corrected as \"Us Always dim migration\"\n",
      "\"d'immigration par\" is corrected as \"dim migration par\"\n",
      "\"excellence CONTR��LE\" is corrected as \"excellence Control E\"\n",
      "\"CONTR��LE RIGOUREUSEMENT\" is corrected as \"Controller Amoureuse Men\"\n",
      "\"RIGOUREUSEMENT l'immigration\" is corrected as \"Figure Element immigration\"\n",
      "\"l'immigration et\" is corrected as \"immigration et\"\n",
      "\"et acc��s\" is corrected as \"et access\"\n",
      "\"acc��s ��\" is corrected as \"access of\"\n",
      "\"�� la\" is corrected as \"of la\"\n",
      "\"la #\" is corrected as \"la a\"\n",
      "\"# GreenCARD\" is corrected as \"a Green Card\"\n",
      "\"GreenCARD !\" is corrected as \"Green Card a\"\n",
      "\"! ��_\" is corrected as \"a ��_\"\n",
      "\"��_ https\" is corrected as \"��_ http\"\n",
      "\"https :\" is corrected as \"http a\"\n",
      "\": //t.co/IHpVhW2BaG\" is corrected as \"a it coli Have Bag\"\n",
      "\"//t.co/IHpVhW2BaG @\" is corrected as \"it coli Have Bag a\"\n",
      "\"@ Shawhelp\" is corrected as \"a Shaw help\"\n",
      "\"Shawhelp what\" is corrected as \"Shaw help what\"\n",
      "\"Canada 's\" is corrected as \"Canada's\"\n",
      "\"violence ?\" is corrected as \"violence a\"\n",
      "\"? L��immigration\" is corrected as \"a Let immigration\"\n",
      "\"L��immigration irr��guli��re\" is corrected as \"Let immigration iron gulf were\"\n",
      "\"irr��guli��re au\" is corrected as \"iron gulf were au\"\n",
      "\"Canada d��cortiqu��e\" is corrected as \"Canada did cortex use\"\n",
      "\"d��cortiqu��e en\" is corrected as \"did cortex use en\"\n",
      "\"questions https\" is corrected as \"questions http\"\n",
      "\"https :\" is corrected as \"http a\"\n",
      "\": //t.co/f4utO5A7ZF\" is corrected as \"a it icon faut 57ff\"\n",
      "\"//t.co/f4utO5A7ZF L'immigration\" is corrected as \"it icon faut 57ff Immigration\"\n",
      "\"L'immigration irr��guli��re\" is corrected as \"Immigration iron gulf were\"\n",
      "\"irr��guli��re au\" is corrected as \"iron gulf were au\"\n",
      "\"Canada d��cortiqu��e\" is corrected as \"Canada did cortex use\"\n",
      "\"d��cortiqu��e en\" is corrected as \"did cortex use en\"\n",
      "\"questions -\" is corrected as \"questions\"\n",
      "\"- https\" is corrected as \"http\"\n",
      "\"https :\" is corrected as \"http a\"\n",
      "\": //t.co/UiBsEZOqas\" is corrected as \"a it icon Use Sofas\"\n",
      "\"//t.co/UiBsEZOqas https\" is corrected as \"it icon Use Sofas http\"\n",
      "\"https :\" is corrected as \"http a\"\n",
      "\": //t.co/j77dEvjoiX\" is corrected as \"a it icon 177 devoid\"\n",
      "\"//t.co/j77dEvjoiX https\" is corrected as \"it icon 177 devoid http\"\n",
      "\"https :\" is corrected as \"http a\"\n",
      "\": //t.co/XXDeIG7Dbu\" is corrected as \"a it cox Deign Du\"\n",
      "\"//t.co/XXDeIG7Dbu Will\" is corrected as \"it cox Deign Du Will\"\n",
      "\"_��_�_ ?\" is corrected as \"_��_�_ a\"\n",
      "\"? ?\" is corrected as \"a a\"\n",
      "\"? From\" is corrected as \"a From\"\n",
      "\"view --\" is corrected as \"view\"\n",
      "\"-- immigration\" is corrected as \"immigration\"\n",
      "\"C��_ https\" is corrected as \"C��_ http\"\n",
      "\"https :\" is corrected as \"http a\"\n",
      "\": //t.co/YAgwmZ8ECp\" is corrected as \"a it copy Am Zweck\"\n",
      "\"//t.co/YAgwmZ8ECp Dan\" is corrected as \"it copy Am Zweck Dan\"\n",
      "\"Murray of��Immigration\" is corrected as \"Murray of immigration\"\n",
      "\"of��Immigration Watch\" is corrected as \"of immigration Watch\"\n",
      "\"is xenophobic\" is corrected as \"is men opsonic\"\n",
      "\"xenophobic racist\" is corrected as \"men opsonic racism\"\n",
      "\"racist fear-mongering\" is corrected as \"racism fear monger ing\"\n",
      "\"fear-mongering liar\" is corrected as \"fear monger ing liar\"\n",
      "\"liar #\" is corrected as \"liar a\"\n",
      "\"# racism\" is corrected as \"a racism\"\n",
      "\"racism #\" is corrected as \"racism a\"\n",
      "\"# canada\" is corrected as \"a canada\"\n",
      "\"canada #\" is corrected as \"canada a\"\n",
      "\"# cdnpoli\" is corrected as \"a campo li\"\n",
      "\"cdnpoli #\" is corrected as \"campo li a\"\n",
      "\"# hatecrime��_\" is corrected as \"a hate crime of\"\n",
      "\"hatecrime��_ https\" is corrected as \"hate crime of http\"\n",
      "\"https :\" is corrected as \"http a\"\n",
      "\": //t.co/kwZ3csvYxM\" is corrected as \"a it cook was say am\"\n",
      "\"//t.co/kwZ3csvYxM Le\" is corrected as \"it cook was say am Le\"\n",
      "\"une vaste\" is corrected as \"une vast\"\n",
      "\"vaste campagne\" is corrected as \"vast champagne\"\n",
      "\"campagne d'immigration\" is corrected as \"champagne dim migration\"\n",
      "\"d'immigration pour\" is corrected as \"dim migration pour\"\n",
      "\"face ��\" is corrected as \"face of\"\n",
      "\"�� son\" is corrected as \"of son\"\n",
      "\"son besoin\" is corrected as \"son lesion\"\n",
      "\"besoin de\" is corrected as \"lesion de\"\n",
      "\"main d'��uvre\" is corrected as \"main d'oeuvre\"\n",
      "\"d'��uvre https\" is corrected as \"d'oeuvre http\"\n",
      "\"https :\" is corrected as \"http a\"\n",
      "\": //t.co/kXdfMGTZzN\" is corrected as \"a it cook Dam Gaze N\"\n",
      "\"//t.co/kXdfMGTZzN L��\" is corrected as \"it cook Dam Gaze N Let\"\n",
      "\"L�� #\" is corrected as \"Let a\"\n",
      "\"# immigration\" is corrected as \"a immigration\"\n",
      "\"immigration irr��guli��re\" is corrected as \"immigration iron gulf were\"\n",
      "\"irr��guli��re au\" is corrected as \"iron gulf were au\"\n",
      "\"au #\" is corrected as \"au a\"\n",
      "\"# Canada\" is corrected as \"a Canada\"\n",
      "\"Canada d��cortiqu��e\" is corrected as \"Canada did cortex use\"\n",
      "\"d��cortiqu��e en\" is corrected as \"did cortex use en\"\n",
      "\"en 5��questions\" is corrected as \"en 5 questions\"\n",
      "\"5��questions https\" is corrected as \"5 questions http\"\n",
      "\"https :\" is corrected as \"http a\"\n",
      "\": //t.co/s3hu1OKKIG\" is corrected as \"a it icons hugo Skin\"\n",
      "\"//t.co/s3hu1OKKIG @\" is corrected as \"it icons hugo Skin a\"\n",
      "\"@ Canadidly\" is corrected as \"a Candidly\"\n",
      "\"Canadidly I\" is corrected as \"Candidly I\"\n",
      "\"I 've\" is corrected as \"I've\"\n",
      "\"'ve read\" is corrected as \"i've read\"\n",
      "\"Immigration Website\" is corrected as \"Immigration Web site\"\n",
      "\"Website Traffic\" is corrected as \"Web site Traffic\"\n",
      "\"Traffic Surges\" is corrected as \"Traffic Purges\"\n",
      "\"Surges And\" is corrected as \"Purges And\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"And Crashes\" is corrected as \"And Clashes\"\n",
      "\"Crashes In\" is corrected as \"Clashes In\"\n",
      "\"Of Trump\" is corrected as \"Of Tramp\"\n",
      "\"Trump #\" is corrected as \"Tramp a\"\n",
      "\"# fasttraffic\" is corrected as \"a fast traffic\"\n",
      "\"fasttraffic ,\" is corrected as \"fast traffic a\"\n",
      "\", #\" is corrected as \"a a\"\n",
      "\"# sitetraffic\" is corrected as \"a site traffic\"\n",
      "\"sitetraffic ,\" is corrected as \"site traffic a\"\n",
      "\", #\" is corrected as \"a a\"\n",
      "\"# website\" is corrected as \"a web site\"\n",
      "\"website ,\" is corrected as \"web site a\"\n",
      "\", #\" is corrected as \"a a\"\n",
      "\"# traffic\" is corrected as \"a traffic\"\n",
      "\"traffic https\" is corrected as \"traffic http\"\n",
      "\"https :\" is corrected as \"http a\"\n",
      "\": //t.co/zRlJ26jnkC\" is corrected as \"a it icon or 269 not\"\n",
      "\"//t.co/zRlJ26jnkC Mr\" is corrected as \"it icon or 269 not Mr\"\n",
      "\"Mr Know-all\" is corrected as \"Mr Know all\"\n",
      "\"Know-all of\" is corrected as \"Know all of\"\n",
      "\"Immigration https\" is corrected as \"Immigration http\"\n",
      "\"https :\" is corrected as \"http a\"\n",
      "\": //t.co/wTQK4QDiKI\" is corrected as \"a it cow Take Wiki\"\n",
      "\"//t.co/wTQK4QDiKI Move\" is corrected as \"it cow Take Wiki Move\"\n",
      "\"Canada @\" is corrected as \"Canada a\"\n",
      "\"@ LadyMadonna___\" is corrected as \"a Lady Madonna of\"\n",
      "\"LadyMadonna___ Oh\" is corrected as \"Lady Madonna of Oh\"\n",
      "\"Oh ,\" is corrected as \"Oh a\"\n",
      "\", immigration\" is corrected as \"a immigration\"\n",
      "\"rules ,\" is corrected as \"rules a\"\n",
      "\", you\" is corrected as \"a you\"\n",
      "\"ca n't\" is corrected as \"can't\"\n",
      "\"n't ...\" is corrected as \"not ...\"\n",
      "\"... https\" is corrected as \"... http\"\n",
      "\"https :\" is corrected as \"http a\"\n",
      "\": //t.co/5LIEVHO7A4\" is corrected as \"a it icon live Hoar\"\n",
      "\"//t.co/5LIEVHO7A4 #\" is corrected as \"it icon live Hoar a\"\n",
      "\"# OnThisDay\" is corrected as \"month is Day\"\n",
      "\"OnThisDay Annette\" is corrected as \"On This Day Annette\"\n",
      "\"Annette Toft\" is corrected as \"Annette Soft\"\n",
      "\"Toft becomes\" is corrected as \"Soft becomes\"\n",
      "\"Canada 's\" is corrected as \"Canada's\"\n",
      "\"since 1945\" is corrected as \"since 195\"\n",
      "\"1945 .\" is corrected as \"195 a\"\n",
      "\". Do\" is corrected as \"a Do\"\n",
      "\"family 's\" is corrected as \"family's\"\n",
      "\"immigration st��_\" is corrected as \"immigration st of\"\n",
      "\"st��_ https\" is corrected as \"st of http\"\n",
      "\"https :\" is corrected as \"http a\"\n",
      "\": //t.co/UvRuw8eR1b\" is corrected as \"a of to coeur under 1\"\n",
      "\"//t.co/UvRuw8eR1b .\" is corrected as \"of to coeur under 1 a\"\n",
      "\". @\" is corrected as \"a a\"\n",
      "\"@ TheEconomist\" is corrected as \"a The Economist\"\n",
      "\"TheEconomist profiles\" is corrected as \"The Economist profile\"\n",
      "\"profiles Canada\" is corrected as \"profile Canada\"\n",
      "\"Canada 's\" is corrected as \"Canada's\"\n",
      "\"policies &\" is corrected as \"policies a\"\n",
      "\"& amp\" is corrected as \"a amp\"\n",
      "\"amp ;\" is corrected as \"amp a\"\n",
      "\"; how\" is corrected as \"a how\"\n",
      "\"success :\" is corrected as \"success a\"\n",
      "\": ��_\" is corrected as \"a ��_\"\n",
      "\"��_ https\" is corrected as \"��_ http\"\n",
      "\"https :\" is corrected as \"http a\"\n",
      "\": //t.co/4K84EE8Y63\" is corrected as \"a it icon 484 1863\"\n",
      "\"//t.co/4K84EE8Y63 Hundreds\" is corrected as \"it icon 484 1863 Hundreds\"\n",
      "\"citizenship ,\" is corrected as \"citizenship a\"\n",
      "\", resident\" is corrected as \"a resident\"\n",
      "\"consultant https\" is corrected as \"consultant http\"\n",
      "\"https :\" is corrected as \"http a\"\n",
      "\": //t.co/x2IfO0EXI2\" is corrected as \"a it cox if exit\"\n",
      "\"//t.co/x2IfO0EXI2 Immigration\" is corrected as \"it cox if exit Immigration\"\n",
      "\"india :\" is corrected as \"india a\"\n",
      "\": an\" is corrected as \"a an\"\n",
      "\"handle :\" is corrected as \"handle a\"\n",
      "\": deyFy\" is corrected as \"a defy\"\n",
      "\"deyFy ''\" is corrected as \"defy'\"\n",
      "\"'' #\" is corrected as \"' a\"\n",
      "\"# Jamaican\" is corrected as \"a Jamaica\"\n",
      "\"Jamaican #\" is corrected as \"Jamaica a\"\n",
      "\"# immigrants\" is corrected as \"a immigrants\"\n",
      "\"immigrants #\" is corrected as \"immigrants a\"\n",
      "\"# Canada\" is corrected as \"a Canada\"\n",
      "\"Canada https\" is corrected as \"Canada http\"\n",
      "\"https :\" is corrected as \"http a\"\n",
      "\": //t.co/vcmfYGadR5\" is corrected as \"a of to comic may Garre\"\n",
      "\"//t.co/vcmfYGadR5 #\" is corrected as \"of to comic may Garre a\"\n",
      "\"# statistics\" is corrected as \"a statistics\"\n",
      "\"statistics #\" is corrected as \"statistics a\"\n",
      "\"# immigration\" is corrected as \"a immigration\"\n",
      "\"immigration ''\" is corrected as \"immigration'\"\n",
      "\"'' Mexican\" is corrected as \"' Mexican\"\n",
      "\"Mexican visa\" is corrected as \"Mexican isa\"\n",
      "\"visa lift\" is corrected as \"isa lift\"\n",
      "\"Canada $\" is corrected as \"Canada a\"\n",
      "\"$ 262M\" is corrected as \"a 262\"\n",
      "\"262M over\" is corrected as \"262 over\"\n",
      "\"decade https\" is corrected as \"decade http\"\n",
      "\"https :\" is corrected as \"http a\"\n",
      "\": //t.co/9i72fRhtij\" is corrected as \"a it icon 972 Ratio\"\n",
      "\"//t.co/9i72fRhtij Are\" is corrected as \"it icon 972 Ratio Are\"\n",
      "\"to #\" is corrected as \"to a\"\n",
      "\"# Canada\" is corrected as \"a Canada\"\n",
      "\"Canada ?\" is corrected as \"Canada a\"\n",
      "\"? ?\" is corrected as \"a a\"\n",
      "\"? ?\" is corrected as \"a a\"\n",
      "\"? Oh\" is corrected as \"a Oh\"\n",
      "\"that 's\" is corrected as \"that's\"\n",
      "\"right ,\" is corrected as \"right a\"\n",
      "\", they\" is corrected as \"a they\"\n",
      "\"and it's��_\" is corrected as \"and it's of\"\n",
      "\"it's��_ https\" is corrected as \"it's of http\"\n",
      "\"https :\" is corrected as \"http a\"\n",
      "\": //t.co/0C5OBfmxLG\" is corrected as \"a it icon cob full G\"\n",
      "\"//t.co/0C5OBfmxLG Here\" is corrected as \"it icon cob full G Here\"\n",
      "\"Richmond ,\" is corrected as \"Richmond a\"\n",
      "\", B.C\" is corrected as \"a Bc\"\n",
      "\"B.C .\" is corrected as \"Bc a\"\n",
      "\". Immigration\" is corrected as \"a Immigration\"\n",
      "\"Sunny Wang\" is corrected as \"Sunny Want\"\n",
      "\"Wang who\" is corrected as \"Want who\"\n",
      "\"... https\" is corrected as \"... http\"\n",
      "\"https :\" is corrected as \"http a\"\n",
      "\": //t.co/YXH5W53srO\" is corrected as \"a it copy How 531 to\"\n",
      "\"//t.co/YXH5W53srO I\" is corrected as \"it copy How 531 roi\"\n",
      "\"a @\" is corrected as \"a a\"\n",
      "\"@ YouTube\" is corrected as \"a Youth be\"\n",
      "\"YouTube playlist\" is corrected as \"Youth be play list\"\n",
      "\"playlist https\" is corrected as \"play list http\"\n",
      "\"https :\" is corrected as \"http a\"\n",
      "\": //t.co/CnEyWN40x3\" is corrected as \"a it icon New 403\"\n",
      "\"//t.co/CnEyWN40x3 Funny\" is corrected as \"it icon New 403 Funny\"\n",
      "\"of Haryanavi\" is corrected as \"of Marya navy\"\n",
      "\"Haryanavi Jat\" is corrected as \"Marya navy At\"\n",
      "\"Jat with\" is corrected as \"At with\"\n",
      "\"Travel Visa-Free\" is corrected as \"Travel Disagree\"\n",
      "\"Visa-Free To\" is corrected as \"Disagree To\"\n",
      "\"Canada https\" is corrected as \"Canada http\"\n",
      "\"https :\" is corrected as \"http a\"\n",
      "\": //t.co/Ec3XHORO2s\" is corrected as \"a it icon Echo Rows\"\n",
      "\"//t.co/Ec3XHORO2s https\" is corrected as \"it icon Echo Rows http\"\n",
      "\"https :\" is corrected as \"http a\"\n",
      "\": //t.co/RQRr5nebcG\" is corrected as \"a it icon Rrrr neck\"\n",
      "\"//t.co/RQRr5nebcG L��immigration\" is corrected as \"it icon Rrrr neck Let immigration\"\n",
      "\"L��immigration irr��guli��re\" is corrected as \"Let immigration iron gulf were\"\n",
      "\"irr��guli��re au\" is corrected as \"iron gulf were au\"\n",
      "\"Canada d��cortiqu��e\" is corrected as \"Canada did cortex use\"\n",
      "\"d��cortiqu��e en\" is corrected as \"did cortex use en\"\n",
      "\"en 5��questions\" is corrected as \"en 5 questions\"\n",
      "\"5��questions https\" is corrected as \"5 questions http\"\n",
      "\"https :\" is corrected as \"http a\"\n",
      "\": //t.co/DkpuKyWmaK\" is corrected as \"a it cold puny Weak\"\n",
      "\"//t.co/DkpuKyWmaK @\" is corrected as \"it cold puny Weak a\"\n",
      "\"@ SweetnessShawnB\" is corrected as \"a Sweetness Shown B\"\n",
      "\"SweetnessShawnB Hes\" is corrected as \"Sweetness Shown B He\"\n",
      "\"Hes the\" is corrected as \"He the\"\n",
      "\"the POS\" is corrected as \"the Pus\"\n",
      "\"POS that\" is corrected as \"Pus that\"\n",
      "\"that ramped\" is corrected as \"that cramped\"\n",
      "\"ramped up\" is corrected as \"cramped up\"\n",
      "\"Canada ,\" is corrected as \"Canada a\"\n",
      "\", among\" is corrected as \"a among\"\n",
      "\"other globalist\" is corrected as \"other global st\"\n",
      "\"globalist policies\" is corrected as \"global st policies\"\n",
      "\"policies .\" is corrected as \"policies a\"\n",
      "\". Canada\" is corrected as \"a Canada\"\n",
      "\"lifted visa\" is corrected as \"lifted isa\"\n",
      "\"visa requirements\" is corrected as \"isa requirements\"\n",
      "\"1 ,\" is corrected as \"1 a\"\n",
      "\", 2016\" is corrected as \"a 201\"\n",
      "\"2016 .\" is corrected as \"201 a\"\n",
      "\". Thoughts\" is corrected as \"a Thoughts\"\n",
      "\"Thoughts ?\" is corrected as \"Thoughts a\"\n",
      "\"? #\" is corrected as \"a a\"\n",
      "\"# visa\" is corrected as \"a isa\"\n",
      "\"visa #\" is corrected as \"isa a\"\n",
      "\"# immigration\" is corrected as \"a immigration\"\n",
      "\"immigration @\" is corrected as \"immigration a\"\n",
      "\"@ HuffingtonPost\" is corrected as \"a Huntington Post\"\n",
      "\"HuffingtonPost people\" is corrected as \"Huntington Post people\"\n",
      "\"they willl\" is corrected as \"they will\"\n",
      "\"willl boot\" is corrected as \"will boot\"\n",
      "['Reminds', 'me', 'of', 'Liberal', 'Immigration', 'Frauds', 'Money', 'avoiding', 'importation', 'from', 'Canada', 'a', 'a', 'campo', 'alps', 'Lock', 'a', 'Could', 'http', 'a', 'it', 'a', 'immigration', 'a', 'integration', 'a', 'canada', 'http', 'a', 'it', 'We', 'want', 'controlled', 'immigration', 'that', 'contributes', 'positively', 'to', 'the', 'Up', 'economy', 'a', 'Same', 'as', 'Australia', 'a', 'amp', 'a', 'Canada', 'a', 'http', 'a', 'it', 'Is', 'the', 'new', 'Monitor', 'immigration', 'fee', 'a', 'head', 'tax', 'a', 'http', 'a', 'it', 'Canada', 'immigration', 'profit', 'influence', 'modern', 'delhi', 'yet', 'china', 'a', 'Of', 'http', 'a', 'it', 'Canada', 'Immigration', 'Minister', 'to', 'of', 'Increase', 'Immigration', 'Numbers', 'http', 'a', 'it', 'http', 'a', 'of', 'Meme', 'les', 'susan', 'Us', 'dim', 'par', 'excellence', 'Controller', 'Figure', 'immigration', 'et', 'access', 'of', 'la', 'a', 'Green', 'a', '��_', 'http', 'a', 'it', 'a', 'Shaw', 'what', 'changes', 'should', 'be', 'made', 'to', \"Canada's\", \"'s\", 'immigration', 'laws', 'due', 'to', 'the', 'influx', 'of', 'immigration', 'and', 'violence', 'a', 'Let', 'iron', 'au', 'Canada', 'did', 'en', '5', 'questions', 'http', 'a', 'it', 'Immigration', 'iron', 'au', 'Canada', 'did', 'en', '5', 'questions', 'http', 'http', 'a', 'it', 'http', 'a', 'it', 'http', 'a', 'it', 'Will', 'Media', 'ask', 'the', 'Liberals', 'if', 'they', 'actually', 'have', 'a', 'solid', 'plan', 'for', 'Canada', '_��_�_', 'a', 'a', 'From', 'my', 'view', 'immigration', 'immigration', 'out', 'of', 'C��_', 'http', 'a', 'it', 'Dan', 'Murray', 'of', 'Watch', 'Canada', 'is', 'men', 'racism', 'fear', 'liar', 'a', 'racism', 'a', 'canada', 'a', 'campo', 'a', 'hate', 'http', 'a', 'it', 'Le', 'Canada', 'lance', 'une', 'vast', 'champagne', 'dim', 'pour', 'faire', 'face', 'of', 'son', 'lesion', 'de', 'main', \"d'oeuvre\", 'http', 'a', 'it', 'Let', 'a', 'immigration', 'iron', 'au', 'a', 'Canada', 'did', 'en', '5', 'http', 'a', 'it', 'a', 'Candidly', \"I've\", \"i've\", 'read', 'the', 'Immigration', 'laws', 'of', 'Canada', 'much', 'stricter', 'than', 'the', 'Us', 'Canada', 'Immigration', 'Web', 'Traffic', 'Purges', 'And', 'Clashes', 'In', 'Wake', 'Of', 'Tramp', 'a', 'fast', 'a', 'a', 'site', 'a', 'a', 'web', 'a', 'a', 'traffic', 'http', 'a', 'it', 'Mr', 'Know', 'of', 'Canada', 'Immigration', 'http', 'a', 'it', 'Move', 'to', 'Canada', 'a', 'Lady', 'Oh', 'a', 'immigration', 'rules', 'a', 'you', \"can't\", 'not', '...', 'http', 'a', 'it', 'month', 'On', 'Annette', 'Soft', 'becomes', \"Canada's\", \"'s\", '2', 'millionth', 'immigrant', 'since', '195', 'a', 'Do', 'you', 'know', 'your', \"family's\", \"'s\", 'immigration', 'st', 'http', 'a', 'of', 'a', 'a', 'The', 'profile', \"Canada's\", \"'s\", 'open', 'immigration', 'policies', 'a', 'amp', 'a', 'how', 'they', 'contribute', 'to', 'our', 'economic', 'success', 'a', '��_', 'http', 'a', 'it', 'Hundreds', 'may', 'lose', 'Canadian', 'citizenship', 'a', 'resident', 'status', 'because', 'of', 'one', 'corrupt', 'immigration', 'consultant', 'http', 'a', 'it', 'Immigration', 'for', 'canada', 'without', 'india', 'a', 'an', 'compassionate', 'handle', 'a', \"defy'\", \"'\", 'a', 'Jamaica', 'a', 'immigrants', 'a', 'Canada', 'http', 'a', 'of', 'a', 'statistics', 'a', \"immigration'\", \"'\", 'Mexican', 'isa', 'lift', 'expected', 'to', 'cost', 'Canada', 'a', '262', 'over', 'a', 'decade', 'http', 'a', 'it', 'Are', 'people', 'still', 'moving', 'to', 'a', 'Canada', 'a', 'a', 'a', 'Oh', \"that's\", \"'s\", 'right', 'a', 'they', 'have', 'real', 'immigration', 'laws', 'and', \"it's\", 'http', 'a', 'it', 'Here', 'are', 'more', 'details', 'on', 'the', 'Richmond', 'a', 'Bc', 'a', 'Immigration', 'Consultant', 'Sunny', 'Want', 'who', 'was', 'sentenced', 'to', '7', 'years', 'in', '...', 'http', 'a', 'it', 'I', 'added', 'a', 'video', 'to', 'a', 'a', 'Youth', 'play', 'http', 'a', 'it', 'Funny', 'Talking', 'of', 'Marya', 'At', 'with', 'Canada', 'Immigration', 'Girl', 'Agent', 'Mexicans', 'Can', 'Now', 'Travel', 'Disagree', 'To', 'Canada', 'http', 'a', 'it', 'http', 'a', 'it', 'Let', 'iron', 'au', 'Canada', 'did', 'en', '5', 'http', 'a', 'it', 'a', 'Sweetness', 'He', 'the', 'Pus', 'that', 'cramped', 'up', 'immigration', 'for', 'Canada', 'a', 'among', 'other', 'global', 'policies', 'a', 'Canada', 'lifted', 'isa', 'requirements', 'to', 'Mexico', 'as', 'of', 'Dec', '1', 'a', '201', 'a', 'Thoughts', 'a', 'a', 'isa', 'a', 'immigration', 'a', 'Huntington', 'people', 'Keep', 'praising', 'Canada', 'and', 'Canada', 'has', 'way', 'stricter', 'immigration', 'laws', 'then', 'us', 'they', 'will', 'boot', 'your', 'liberal', 'American', 'ass']\n"
     ]
    }
   ],
   "source": [
    "print(correct_tocknized_text(twitter_data_tockenize))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Research Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Neural network\" is corrected as \"Neutral network\"\n",
      "\"for multi-task\" is corrected as \"for multi ask\"\n",
      "\"multi-task learning\" is corrected as \"multi ask learning\"\n",
      "\"learning ,\" is corrected as \"learning a\"\n",
      "\", which\" is corrected as \"a which\"\n",
      "\"and task-invariant\" is corrected as \"and task in variant\"\n",
      "\"task-invariant features\" is corrected as \"task in variant features\"\n",
      "\"features .\" is corrected as \"features a\"\n",
      "\". However\" is corrected as \"a However\"\n",
      "\"However ,\" is corrected as \"However a\"\n",
      "\", in\" is corrected as \"a in\"\n",
      "\"approaches ,\" is corrected as \"approaches a\"\n",
      "\", the\" is corrected as \"a the\"\n",
      "\"by task-specific\" is corrected as \"by task specific\"\n",
      "\"task-specific features\" is corrected as \"task specific features\"\n",
      "\"tasks .\" is corrected as \"tasks a\"\n",
      "\". In\" is corrected as \"a In\"\n",
      "\"paper ,\" is corrected as \"paper a\"\n",
      "\", we\" is corrected as \"a we\"\n",
      "\"an adversarial\" is corrected as \"an adversary l\"\n",
      "\"adversarial multi-task\" is corrected as \"adversary l multi ask\"\n",
      "\"multi-task learning\" is corrected as \"multi ask learning\"\n",
      "\"framework ,\" is corrected as \"framework a\"\n",
      "\", alleviating\" is corrected as \"a alleviating\"\n",
      "\"other .\" is corrected as \"other a\"\n",
      "\". We\" is corrected as \"a We\"\n",
      "\"tasks ,\" is corrected as \"tasks a\"\n",
      "\", which\" is corrected as \"a which\"\n",
      "\"approach .\" is corrected as \"approach a\"\n",
      "\". Besides\" is corrected as \"a Besides\"\n",
      "\"Besides ,\" is corrected as \"Besides a\"\n",
      "\", we\" is corrected as \"a we\"\n",
      "\"as off-the-shelf\" is corrected as \"as off the shelf\"\n",
      "\"off-the-shelf knowledge\" is corrected as \"off the shelf knowledge\"\n",
      "\"tasks .\" is corrected as \"tasks a\"\n",
      "\". Multi-task\" is corrected as \"a Multi ask\"\n",
      "\"Multi-task learning\" is corrected as \"Multi ask learning\"\n",
      "\"tasks .\" is corrected as \"tasks a\"\n",
      "\". Recently\" is corrected as \"a Recently\"\n",
      "\"Recently ,\" is corrected as \"Recently a\"\n",
      "\", neural-based\" is corrected as \"a neutral based\"\n",
      "\"neural-based models\" is corrected as \"neutral based models\"\n",
      "\"for multi-task\" is corrected as \"for multi ask\"\n",
      "\"multi-task learning\" is corrected as \"multi ask learning\"\n",
      "\"popular ,\" is corrected as \"popular a\"\n",
      "\", ranging\" is corrected as \"a ranging\"\n",
      "\"vision (\" is corrected as \"vision a\"\n",
      "\"( Misra\" is corrected as \"a Misha\"\n",
      "\"Misra et\" is corrected as \"Misha et\"\n",
      "\"et al.\" is corrected as \"et all\"\n",
      "\"al. ,\" is corrected as \"all a\"\n",
      "\", 2016\" is corrected as \"a 201\"\n",
      "\"2016 ;\" is corrected as \"201 a\"\n",
      "\"; Zhang\" is corrected as \"a Hang\"\n",
      "\"Zhang et\" is corrected as \"Hang et\"\n",
      "\"et al.\" is corrected as \"et all\"\n",
      "\"al. ,\" is corrected as \"all a\"\n",
      "\", 2014\" is corrected as \"a 201\"\n",
      "\"2014 )\" is corrected as \"201 a\"\n",
      "\") to\" is corrected as \"a to\"\n",
      "\"processing (\" is corrected as \"processing a\"\n",
      "\"( Collobert\" is corrected as \"a Follower t\"\n",
      "\"Collobert andWeston\" is corrected as \"Follower t andwew ton\"\n",
      "\"andWeston ,\" is corrected as \"andwew ton a\"\n",
      "\", 2008\" is corrected as \"a 200\"\n",
      "\"2008 ;\" is corrected as \"200 a\"\n",
      "\"; Luong\" is corrected as \"a Long\"\n",
      "\"Luong et\" is corrected as \"Long et\"\n",
      "\"et al.\" is corrected as \"et all\"\n",
      "\"al. ,\" is corrected as \"all a\"\n",
      "\", 2015\" is corrected as \"a 201\"\n",
      "\"2015 )\" is corrected as \"201 a\"\n",
      "\") ,\" is corrected as \"a a\"\n",
      "\", since\" is corrected as \"a since\"\n",
      "\"tasks .\" is corrected as \"tasks a\"\n",
      "\". However\" is corrected as \"a However\"\n",
      "\"However ,\" is corrected as \"However a\"\n",
      "\", most\" is corrected as \"a most\"\n",
      "\"on multi-task\" is corrected as \"on multi ask\"\n",
      "\"multi-task learning\" is corrected as \"multi ask learning\"\n",
      "\"learning (\" is corrected as \"learning a\"\n",
      "\"( Liu\" is corrected as \"a Lie\"\n",
      "\"Liu et\" is corrected as \"Lie et\"\n",
      "\"et al.\" is corrected as \"et all\"\n",
      "\"al. ,\" is corrected as \"all a\"\n",
      "\", 2016c\" is corrected as \"a 201\"\n",
      "\"2016c ,\" is corrected as \"201 a\"\n",
      "\", b\" is corrected as \"a b\"\n",
      "\"b )\" is corrected as \"b a\"\n",
      "\") attempts\" is corrected as \"a attempts\"\n",
      "\"spaces ,\" is corrected as \"spaces a\"\n",
      "\", merely\" is corrected as \"a merely\"\n",
      "\"whether parameters\" is corrected as \"whether parameter\"\n",
      "\"parameters of\" is corrected as \"parameter of\"\n",
      "\"shared .\" is corrected as \"shared a\"\n",
      "\". As\" is corrected as \"a As\"\n",
      "\"Figure 1-\" is corrected as \"Figure 1\"\n",
      "\"1- (\" is corrected as \"1 a\"\n",
      "\"( a\" is corrected as \"a a\"\n",
      "\"a )\" is corrected as \"a a\"\n",
      "\") ,\" is corrected as \"a a\"\n",
      "\", the\" is corrected as \"a the\"\n",
      "\"general shared-private\" is corrected as \"general shared private\"\n",
      "\"shared-private model\" is corrected as \"shared private model\"\n",
      "\"task :\" is corrected as \"task a\"\n",
      "\": one\" is corrected as \"a one\"\n",
      "\"store task-dependent\" is corrected as \"store task dependent\"\n",
      "\"task-dependent features\" is corrected as \"task dependent features\"\n",
      "\"features ,\" is corrected as \"features a\"\n",
      "\", the\" is corrected as \"a the\"\n",
      "\"features .\" is corrected as \"features a\"\n",
      "\". The\" is corrected as \"a The\"\n",
      "\"unnecessary task-specific\" is corrected as \"unnecessary task specific\"\n",
      "\"task-specific features\" is corrected as \"task specific features\"\n",
      "\"features ,\" is corrected as \"features a\"\n",
      "\", while\" is corrected as \"a while\"\n",
      "\"some sharable\" is corrected as \"some arable\"\n",
      "\"sharable features\" is corrected as \"arable features\"\n",
      "\"space ,\" is corrected as \"space a\"\n",
      "\", suffering\" is corrected as \"a suffering\"\n",
      "\"redundancy .\" is corrected as \"redundancy a\"\n",
      "\". Taking\" is corrected as \"a Taking\"\n",
      "\"examples ,\" is corrected as \"examples a\"\n",
      "\", which\" is corrected as \"a which\"\n",
      "\"tasks :\" is corrected as \"tasks a\"\n",
      "\": Movie\" is corrected as \"a Movie\"\n",
      "\"reviews .\" is corrected as \"reviews a\"\n",
      "\". The\" is corrected as \"a The\"\n",
      "\"use .\" is corrected as \"use a\"\n",
      "\". This\" is corrected as \"a This\"\n",
      "\"boring .\" is corrected as \"boring a\"\n",
      "\". The\" is corrected as \"a The\"\n",
      "\"word �infantile�\" is corrected as \"word infantile\"\n",
      "\"�infantile� indicates\" is corrected as \"infantile indicates\"\n",
      "\"task .\" is corrected as \"task a\"\n",
      "\". However\" is corrected as \"a However\"\n",
      "\"However ,\" is corrected as \"However a\"\n",
      "\", the\" is corrected as \"a the\"\n",
      "\"general shared-private\" is corrected as \"general shared private\"\n",
      "\"shared-private model\" is corrected as \"shared private model\"\n",
      "\"the task-specific\" is corrected as \"the task specific\"\n",
      "\"task-specific word\" is corrected as \"task specific word\"\n",
      "\"word �infantile�\" is corrected as \"word infantile\"\n",
      "\"�infantile� in\" is corrected as \"infantile in\"\n",
      "\"space ,\" is corrected as \"space a\"\n",
      "\", leaving\" is corrected as \"a leaving\"\n",
      "\"tasks .\" is corrected as \"tasks a\"\n",
      "\". Additionally\" is corrected as \"a Additional y\"\n",
      "\"Additionally ,\" is corrected as \"Additional y a\"\n",
      "\", the\" is corrected as \"a the\"\n",
      "\"features .\" is corrected as \"features a\"\n",
      "\". To\" is corrected as \"a To\"\n",
      "\"problem ,\" is corrected as \"problem a\"\n",
      "\", in\" is corrected as \"a in\"\n",
      "\"an adversarial\" is corrected as \"an adversary l\"\n",
      "\"adversarial multi-task\" is corrected as \"adversary l multi ask\"\n",
      "\"multi-task framework\" is corrected as \"multi ask framework\"\n",
      "\"framework ,\" is corrected as \"framework a\"\n",
      "\", in\" is corrected as \"a in\"\n",
      "\"in herently\" is corrected as \"inherently\"\n",
      "\"herently disjoint\" is corrected as \"recently dis joint\"\n",
      "\"disjoint by\" is corrected as \"dis joint by\"\n",
      "\"introducing orthogonality\" is corrected as \"introducing orthodox amity\"\n",
      "\"orthogonality constraints.Specifically\" is corrected as \"orthodox amity constraint specifically\"\n",
      "\"constraints.Specifically ,\" is corrected as \"constraint specifically a\"\n",
      "\", we\" is corrected as \"a we\"\n",
      "\"a generic\" is corrected as \"a genetic\"\n",
      "\"generic shared\" is corrected as \"genetic shared\"\n",
      "\"sequence .\" is corrected as \"sequence a\"\n",
      "['Neutral', 'network', 'models', 'have', 'shown', 'their', 'promising', 'opportunities', 'for', 'multi', 'learning', 'a', 'which', 'focus', 'on', 'learning', 'the', 'shared', 'layers', 'to', 'extract', 'the', 'common', 'and', 'task', 'features', 'a', 'However', 'a', 'in', 'most', 'existing', 'approaches', 'a', 'the', 'extracted', 'shared', 'features', 'are', 'prone', 'to', 'be', 'contaminated', 'by', 'task', 'features', 'or', 'the', 'noise', 'brought', 'by', 'other', 'tasks', 'a', 'In', 'this', 'paper', 'a', 'we', 'propose', 'an', 'adversary', 'multi', 'learning', 'framework', 'a', 'alleviating', 'the', 'shared', 'and', 'private', 'latent', 'feature', 'spaces', 'from', 'interfering', 'with', 'each', 'other', 'a', 'We', 'conduct', 'extensive', 'experiments', 'on', '16', 'different', 'text', 'classification', 'tasks', 'a', 'which', 'demonstrates', 'the', 'benefits', 'of', 'our', 'approach', 'a', 'Besides', 'a', 'we', 'show', 'that', 'the', 'shared', 'knowledge', 'learned', 'by', 'our', 'proposed', 'model', 'can', 'be', 'regarded', 'as', 'off', 'knowledge', 'and', 'easily', 'transferred', 'to', 'new', 'tasks', 'a', 'Multi', 'learning', 'is', 'an', 'effective', 'approach', 'to', 'improve', 'the', 'performance', 'of', 'a', 'single', 'task', 'with', 'the', 'help', 'of', 'other', 'related', 'tasks', 'a', 'Recently', 'a', 'neutral', 'models', 'for', 'multi', 'learning', 'have', 'become', 'very', 'popular', 'a', 'ranging', 'from', 'computer', 'vision', 'a', 'Misha', 'et', 'all', 'a', '201', 'a', 'Hang', 'et', 'all', 'a', '201', 'a', 'to', 'natural', 'language', 'processing', 'a', 'Follower', 'andwew', 'a', '200', 'a', 'Long', 'et', 'all', 'a', '201', 'a', 'a', 'since', 'they', 'provide', 'a', 'convenient', 'way', 'of', 'combining', 'information', 'from', 'multiple', 'tasks', 'a', 'However', 'a', 'most', 'existing', 'work', 'on', 'multi', 'learning', 'a', 'Lie', 'et', 'all', 'a', '201', 'a', 'b', 'a', 'attempts', 'to', 'divide', 'the', 'features', 'of', 'different', 'tasks', 'into', 'private', 'and', 'shared', 'spaces', 'a', 'merely', 'based', 'on', 'whether', 'parameter', 'of', 'some', 'components', 'should', 'be', 'shared', 'a', 'As', 'shown', 'in', 'Figure', '1', 'a', 'a', 'a', 'a', 'the', 'general', 'shared', 'model', 'introduces', 'two', 'feature', 'spaces', 'for', 'any', 'task', 'a', 'one', 'is', 'used', 'to', 'store', 'task', 'features', 'a', 'the', 'other', 'is', 'used', 'to', 'capture', 'shared', 'features', 'a', 'The', 'major', 'limitation', 'of', 'this', 'framework', 'is', 'that', 'the', 'shared', 'feature', 'space', 'could', 'contain', 'some', 'unnecessary', 'task', 'features', 'a', 'while', 'some', 'arable', 'features', 'could', 'also', 'be', 'mixed', 'in', 'private', 'space', 'a', 'suffering', 'from', 'feature', 'redundancy', 'a', 'Taking', 'the', 'following', 'two', 'sentences', 'as', 'examples', 'a', 'which', 'are', 'extracted', 'from', 'two', 'different', 'sentiment', 'classification', 'tasks', 'a', 'Movie', 'reviews', 'and', 'Baby', 'products', 'reviews', 'a', 'The', 'infantile', 'cart', 'is', 'simple', 'and', 'easy', 'to', 'use', 'a', 'This', 'kind', 'of', 'humour', 'is', 'infantile', 'and', 'boring', 'a', 'The', 'word', 'infantile', 'indicates', 'negative', 'sentiment', 'in', 'Movie', 'task', 'while', 'it', 'is', 'neutral', 'in', 'Baby', 'task', 'a', 'However', 'a', 'the', 'general', 'shared', 'model', 'could', 'place', 'the', 'task', 'word', 'infantile', 'in', 'a', 'shared', 'space', 'a', 'leaving', 'potential', 'hazards', 'for', 'other', 'tasks', 'a', 'Additional', 'a', 'the', 'capacity', 'of', 'shared', 'space', 'could', 'also', 'be', 'wasted', 'by', 'some', 'unnecessary', 'features', 'a', 'To', 'address', 'this', 'problem', 'a', 'in', 'this', 'paper', 'we', 'propose', 'an', 'adversary', 'multi', 'framework', 'a', 'in', 'which', 'the', 'shared', 'and', 'private', 'feature', 'spaces', 'are', 'inherently', 'recently', 'dis', 'by', 'introducing', 'orthodox', 'constraint', 'a', 'we', 'design', 'a', 'genetic', 'shared', 'private', 'learning', 'framework', 'to', 'model', 'the', 'text', 'sequence', 'a']\n"
     ]
    }
   ],
   "source": [
    "print(correct_tocknized_text(research_data_tockenize))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "show_stemm = 10\n",
    "def stem_tockens(tockenized_text):\n",
    "    stemmed_text = []\n",
    "    for word in tockenized_text:\n",
    "        stemmed_text.append(stemmer.stem(word))\n",
    "    print(tockenized_text[0:show_stemm])\n",
    "    print(stemmed_text[0:show_stemm])\n",
    "    return stemmed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Student Course Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Honestly', 'last', 'seven', 'lectures', 'are', 'good', '.', 'Lectures', 'are', 'understandable']\n",
      "['honestli', 'last', 'seven', 'lectur', 'are', 'good', '.', 'lectur', 'are', 'understand']\n",
      "Written to ../output/stemmer/assignment_output.txt\n"
     ]
    }
   ],
   "source": [
    "result = stem_tockens(student_feedback_tockenize)\n",
    "write_to_file(result, 'stemmer/{}_output.txt'.format(TEXT.asn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Twitter Feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Reminds', 'me', 'of', 'Liberal', 'Immigration', 'Fraudster', 'Monsef', 'avoiding', 'deportation', 'from']\n",
      "['remind', 'me', 'of', 'liber', 'immigr', 'fraudster', 'monsef', 'avoid', 'deport', 'from']\n",
      "Written to ../output/stemmer/twitter_output.txt\n"
     ]
    }
   ],
   "source": [
    "result = stem_tockens(twitter_data_tockenize)\n",
    "write_to_file(result, 'stemmer/{}_output.txt'.format(TEXT.twt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Research Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Neural', 'network', 'models', 'have', 'shown', 'their', 'promising', 'opportunities', 'for', 'multi-task']\n",
      "['neural', 'network', 'model', 'have', 'shown', 'their', 'promis', 'opportun', 'for', 'multi-task']\n",
      "Written to ../output/stemmer/research_output.txt\n"
     ]
    }
   ],
   "source": [
    "result = stem_tockens(research_data_tockenize)\n",
    "write_to_file(result, 'stemmer/{}_output.txt'.format(TEXT.rsh))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer() \n",
    "show_lemm = 10\n",
    "def lemmatize_tockens(tockenized_text):\n",
    "    lemmatized_text = []\n",
    "    for word in tockenized_text:\n",
    "        lemmatized_text.append(lemmatizer.lemmatize(word))\n",
    "    print(tockenized_text[0:show_lemm])    \n",
    "    print(lemmatized_text[0:show_lemm])\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Student Course Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Honestly', 'last', 'seven', 'lectures', 'are', 'good', '.', 'Lectures', 'are', 'understandable']\n",
      "['Honestly', 'last', 'seven', 'lecture', 'are', 'good', '.', 'Lectures', 'are', 'understandable']\n",
      "Written to ../output/lemmatize/assignment_output.txt\n"
     ]
    }
   ],
   "source": [
    "result = lemmatize_tockens(student_feedback_tockenize)\n",
    "write_to_file(result, 'lemmatize/{}_output.txt'.format(TEXT.asn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Twitter Feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Reminds', 'me', 'of', 'Liberal', 'Immigration', 'Fraudster', 'Monsef', 'avoiding', 'deportation', 'from']\n",
      "['Reminds', 'me', 'of', 'Liberal', 'Immigration', 'Fraudster', 'Monsef', 'avoiding', 'deportation', 'from']\n",
      "Written to ../output/lemmatize/twitter_output.txt\n"
     ]
    }
   ],
   "source": [
    "result = lemmatize_tockens(twitter_data_tockenize)\n",
    "write_to_file(result, 'lemmatize/{}_output.txt'.format(TEXT.twt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Research Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Neural', 'network', 'models', 'have', 'shown', 'their', 'promising', 'opportunities', 'for', 'multi-task']\n",
      "['Neural', 'network', 'model', 'have', 'shown', 'their', 'promising', 'opportunity', 'for', 'multi-task']\n",
      "Written to ../output/lemmatize/research_output.txt\n"
     ]
    }
   ],
   "source": [
    "result = lemmatize_tockens(research_data_tockenize)\n",
    "write_to_file(result, 'lemmatize/{}_output.txt'.format(TEXT.rsh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('py376': virtualenv)",
   "language": "python",
   "name": "python37664bitpy376virtualenvc1e1d512084149469623763e9dd746d6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
