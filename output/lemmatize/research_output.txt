Neural network model have shown their promising opportunity for multi-task learning , which focus on learning the shared layer to extract the common and task-invariant feature . However , in most existing approach , the extracted shared feature are prone to be contaminated by task-specific feature or the noise brought by other task . In this paper , we propose an adversarial multi-task learning framework , alleviating the shared and private latent feature space from interfering with each other . We conduct extensive experiment on 16 different text classification task , which demonstrates the benefit of our approach . Besides , we show that the shared knowledge learned by our proposed model can be regarded a off-the-shelf knowledge and easily transferred to new task . Multi-task learning is an effective approach to improve the performance of a single task with the help of other related task . Recently , neural-based model for multi-task learning have become very popular , ranging from computer vision ( Misra et al. , 2016 ; Zhang et al. , 2014 ) to natural language processing ( Collobert andWeston , 2008 ; Luong et al. , 2015 ) , since they provide a convenient way of combining information from multiple task . However , most existing work on multi-task learning ( Liu et al. , 2016c , b ) attempt to divide the feature of different task into private and shared space , merely based on whether parameter of some component should be shared . As shown in Figure 1- ( a ) , the general shared-private model introduces two feature space for any task : one is used to store task-dependent feature , the other is used to capture shared feature . The major limitation of this framework is that the shared feature space could contain some unnecessary task-specific feature , while some sharable feature could also be mixed in private space , suffering from feature redundancy . Taking the following two sentence a example , which are extracted from two different sentiment classification task : Movie review and Baby product review . The infantile cart is simple and easy to use . This kind of humour is infantile and boring . The word �infantile� indicates negative sentiment in Movie task while it is neutral in Baby task . However , the general shared-private model could place the task-specific word �infantile� in a shared space , leaving potential hazard for other task . Additionally , the capacity of shared space could also be wasted by some unnecessary feature . To address this problem , in this paper we propose an adversarial multi-task framework , in which the shared and private feature space are in herently disjoint by introducing orthogonality constraints.Specifically , we design a generic shared private learning framework to model the text sequence . 